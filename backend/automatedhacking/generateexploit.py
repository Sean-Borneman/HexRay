#!/usr/bin/env python3
"""
Exploit generator scaffold.

Combines vulnerability findings + typed C context and emits:
 - auto_combined.txt: consolidated context for review
 - auto_exploit.py: a runner that attempts to trigger findings and search output
   for a flag of a given format (default regex: FortID{...}).

This is a generic harness, not a tailored exploit. It runs the target with a set
of payloads (from payloads.json) through argv or stdin to try to elicit a flag.
"""
from __future__ import annotations

import json
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import Dict, Optional


def _read_text(path: Optional[Path]) -> str:
    if not path:
        return ''
    try:
        return Path(path).read_text(errors='ignore')
    except Exception:
        return ''


def _extract_code_from_llm(text: str) -> str:
    # Prefer a fenced python block
    m = re.search(r"```(?:python)?\s*([\s\S]*?)```", text, re.IGNORECASE)
    if m:
        return m.group(1).strip()
    return text.strip()


def generate_exploit(
    vulnerabilities_json: str,
    typed_c_path: Optional[str],
    original_exe: str,
    payloads_json: Optional[str] = None,
    out_dir: Optional[str] = None,
    flag_regex: str = r"FortID\{[^}]+\}",
    combined_path: Optional[str] = None,
) -> Dict[str, str]:
    """
    Use Anthropic to generate an exploit.py given typed C, vulnerabilities, and combined C/data.
    Falls back to a no-op stub if the client is unavailable.
    """
    results_dir = Path(out_dir or './storage/results')
    working_dir = Path('./storage/working')
    results_dir.mkdir(parents=True, exist_ok=True)
    working_dir.mkdir(parents=True, exist_ok=True)

    # Inputs
    vulns_p = Path(vulnerabilities_json)
    typed_p = Path(typed_c_path) if typed_c_path else None
    comb_p = Path(combined_path) if combined_path else None
    exe_p = Path(original_exe)

    vulns_text = _read_text(vulns_p)
    # Optionally parse to surface techniques verbatim in the prompt
    techniques_str = ''
    notes_str = ''
    try:
        _vobj = json.loads(vulns_text) if vulns_text else {}
        _techs = _vobj.get('techniques') or []
        if isinstance(_techs, list) and _techs:
            techniques_str = "\n".join(f"- {t}" for t in _techs if isinstance(t, str))
        _notes = _vobj.get('llm_notes') or ''
        if isinstance(_notes, str) and _notes.strip():
            notes_str = _notes.strip()
    except Exception:
        pass
    typed_text = _read_text(typed_p)
    combined_text = _read_text(comb_p)
    # Prefer decompiler data directly rather than an external objdump file
    # Primary source: decompiled_output/ALL_DATA.txt (from ghidraDecompileTWOFiles.py)
    data_text = ''
    try:
        all_data_path = Path('./decompiled_output/ALL_DATA.txt')
        if all_data_path.exists():
            data_text = _read_text(all_data_path)
        else:
            # Fallback: concatenate any files under decompiled_output/data/*.txt
            data_dir = Path('./decompiled_output/data')
            if data_dir.exists():
                parts = []
                for p in sorted(data_dir.glob('*.txt')):
                    try:
                        parts.append(p.read_text(errors='ignore'))
                    except Exception:
                        pass
                data_text = "\n\n".join(parts)
    except Exception:
        data_text = ''

    # Trim to keep prompt size reasonable
    def clip(s: str, n: int) -> str:
        return s[:n] if len(s) > n else s

    vulns_snip = clip(vulns_text, 60_000)
    typed_snip = clip(typed_text, 120_000)
    combined_snip = clip(combined_text, 150_000)
    data_snip = clip(data_text, 120_000)

    # Build a consolidated context file
    auto_combined = working_dir / 'auto_combined.txt'
    with open(auto_combined, 'w', encoding='utf-8', errors='ignore') as f:
        f.write('=== TARGET_PATH ===\n')
        f.write(str(exe_p))
        f.write('\n\n=== FLAG_REGEX ===\n')
        f.write(flag_regex)
        f.write('\n\n=== VULNERABILITIES_JSON ===\n')
        f.write(vulns_snip)
        f.write('\n\n=== TYPED_C_START ===\n')
        f.write(typed_snip)
        f.write('\n=== TYPED_C_END ===\n')
        f.write('\n=== COMBINED_INPUT_START ===\n')
        f.write(combined_snip)
        f.write('\n=== COMBINED_INPUT_END ===\n')
        if data_snip:
            f.write('\n=== ALL_DATA_EXCERPT_START ===\n')
            f.write(data_snip)
            f.write('\n=== ALL_DATA_EXCERPT_END ===\n')

    # Try to import the analyzer and call Anthropic
    try:
        from llm_analyzer import LLMAnalyzer  # type: ignore
    except Exception:
        LLMAnalyzer = None  # type: ignore

    exploit_py = results_dir / 'exploit.py'
    # Per-attempt artifacts will be suffixed with _attempt{n}

    # Helper to build the prompt (optionally with feedback from a previous attempt)
    def build_prompt(feedback: str | None) -> str:
        parts = [
            "You are an expert CTF exploit developer.\n",
            "Task: Produce a Windows-compatible Python 3 script named exploit.py that intelligently interacts with the\n",
            "target binary using insights from the provided typed C, combined code/data, and vulnerability hints.\n",
            "Determine likely inputs, argument patterns, and interaction flows (stdin/argv) based on the program logic.\n",
            "Do not brute-force arbitrary combinations; instead, reason about the expected inputs and craft them accordingly.\n",
            "The provided flag format is a heuristic: use it to reduce and prioritize candidates,\n",
            "but do not assume the program always prints the full flag directly; rely on clear success cues when needed.\n",
            "Critically: USE BOTH the typed C and ALL_DATA excerpts to derive an exact method; embed any derived constants/tables directly in the script so it is self-contained.\n",
            "Method checklist: infer method from typed C + ALL_DATA; implement it; run the target; verify via success cues and/or the flag regex; exit 0 only on success.\n",
            "When the program outputs a flag matching the provided format, print that flag to stdout exactly once and exit 0.\n",
            "If nothing is found, exit 1.\n",
            "Requirements: standard library only; short timeouts; capture stdout+stderr; robust error handling;\n",
            "search for the flag with regex; output only the Python code (no prose or markdown).\n\n",
            f"Target path: {exe_p}\n",
            f"Flag format (regex): {flag_regex}\n\n",
            "Vulnerabilities (JSON):\n", vulns_snip, "\n\n",
        ]
        if techniques_str:
            parts.extend(["Techniques (verbatim from prior step):\n", techniques_str, "\n\n"])
        if notes_str:
            parts.extend(["Analyst Notes:\n", notes_str, "\n\n"])
        if feedback:
            parts.extend(["Previous attempt feedback (adapt your approach):\n", feedback, "\n\n"])
        parts.extend([
            "Typed C (may be partial):\n===TYPED_C_START===\n", typed_snip, "\n===TYPED_C_END===\n\n",
            "Combined C/data context:\n===COMBINED_INPUT_START===\n", combined_snip, "\n===COMBINED_INPUT_END===\n\n",
            ("Excerpt from decompiled data (ALL_DATA).\n===ALL_DATA_EXCERPT_START===\n" + data_snip + "\n===ALL_DATA_EXCERPT_END===\n\n" if data_snip else ''),
            "If the ALL_DATA excerpt contains relevant bytes/structures (e.g., patterns, arrays), transform them into inputs the program expects, and integrate that into the script's logic.\n",
        ])

        # Restate key data at the end and require the script to embed a usable version
        if data_snip:
            parts.extend([
                "Restated ALL_DATA to interpret (embed a usable representation in the script):\n",
                "===DATA_RESTATE_START===\n", data_snip, "\n===DATA_RESTATE_END===\n\n",
            ])

        parts.append("Output only valid Python code for exploit.py (no markdown fences).")
        return ''.join(parts)

    def llm_generate_code(prompt_text: str, prompt_path: Path, report_path: Path) -> str:
        text = ''
        if LLMAnalyzer is not None:
            analyzer = LLMAnalyzer()
            if getattr(analyzer, 'client', None) is not None:
                try:
                    response = analyzer.client.messages.create(
                        model=analyzer.model,
                        max_tokens=4000,
                        temperature=0,
                        messages=[{"role": "user", "content": prompt_text}],
                    )
                    text = response.content[0].text if response and getattr(response, 'content', None) else ''
                    tokens_used = getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') else 0
                    if tokens_used:
                        print(f"[AutoHack][LLM] tokens_used={tokens_used}")
                except Exception as e:
                    text = f"# LLM error: {e}\nprint('No exploit generated')\n"
        # Persist prompt and raw output
        try:
            prompt_path.write_text(prompt_text, encoding='utf-8', errors='ignore')
        except Exception:
            pass
        try:
            report_path.write_text(text, encoding='utf-8', errors='ignore')
        except Exception:
            pass
        return _extract_code_from_llm(text)

    # Attempt loop: generate and run exploit up to 3 times, feeding back context
    max_attempts = 2
    found_flag = None
    last_stdout = ''
    last_stderr = ''
    last_returncode = None
    for attempt in range(1, max_attempts + 1):
        feedback = None
        if attempt > 1:
            # Include a short feedback snippet from the previous run
            fb_lines = []
            fb_lines.append(f"Return code: {last_returncode}")
            if last_stdout:
                fb_lines.append("STDOUT (first 800 chars):\n" + last_stdout[:800])
            if last_stderr:
                fb_lines.append("STDERR (first 800 chars):\n" + last_stderr[:800])
            feedback = "\n\n".join(fb_lines)

        prompt_text = build_prompt(feedback)
        prompt_file = working_dir / f"autohack_exploit_prompt_attempt{attempt}.txt"
        report_file = working_dir / f"autohack_exploit_llm_report_attempt{attempt}.txt"
        code = llm_generate_code(prompt_text, prompt_file, report_file)

        # Write code to per-attempt file and to exploit.py
        exploit_attempt = working_dir / f"exploit_attempt{attempt}.py"
        if code:
            exploit_attempt.write_text(code, encoding='utf-8', errors='ignore')
            try:
                exploit_py.write_text(code, encoding='utf-8', errors='ignore')
            except Exception:
                pass
        else:
            exploit_attempt.write_text("print('No exploit generated')\n", encoding='utf-8')
            try:
                exploit_py.write_text("print('No exploit generated')\n", encoding='utf-8')
            except Exception:
                pass

        # Run the generated exploit
        log_file = working_dir / f'exhibit_exploit_run_log_attempt{attempt}.txt'
        result_json = working_dir / f'exhibit_exploit_run_attempt{attempt}.json'
        try:
            run = subprocess.run([sys.executable, str(exploit_attempt)], capture_output=True, text=True, timeout=240)
            out_text = (run.stdout or '') + "\n" + (run.stderr or '')
            last_stdout, last_stderr, last_returncode = (run.stdout or ''), (run.stderr or ''), run.returncode
            try:
                log_file.write_text(out_text, encoding='utf-8', errors='ignore')
            except Exception:
                pass
            m = re.search(flag_regex, out_text)
            found_flag = m.group(0) if m else None
            try:
                result_payload = {
                    'attempt': attempt,
                    'script': str(exploit_attempt),
                    'returncode': run.returncode,
                    'flag_found': bool(found_flag),
                    'flag': found_flag,
                    'stdout_len': len(run.stdout or ''),
                    'stderr_len': len(run.stderr or ''),
                }
                result_json.write_text(json.dumps(result_payload, indent=2))
            except Exception:
                pass
            if found_flag:
                break
        except subprocess.TimeoutExpired:
            last_stdout, last_stderr, last_returncode = '', 'TIMEOUT', 'TIMEOUT'
            continue
        except Exception as e:
            last_stdout, last_stderr, last_returncode = '', str(e), 'ERROR'
            continue

    print(f"[AutoHack] Wrote: {auto_combined}")
    print(f"[AutoHack] Latest exploit: {exploit_py}")

    found_flag_file = results_dir / 'found_flag.txt'
    if found_flag:
        try:
            found_flag_file.write_text(found_flag + "\n")
        except Exception:
            pass
        print(f"[AutoHack] Flag detected and saved: {found_flag_file}")
    else:
        print("[AutoHack] No flag detected after retries. See attempt logs for details.")

    return {
        'auto_combined': str(auto_combined),
        'exploit_script': str(exploit_py),
        'found_flag_file': str(found_flag_file),
        'run_log': str(log_file),
        'run_result': str(result_json),
    }


def run_cli():
    import argparse
    p = argparse.ArgumentParser(description='Generate exploit.py via LLM and run it')
    p.add_argument('--vulns', required=True, help='Path to vulnerabilities.json')
    p.add_argument('--typed', help='Path to typed C file')
    p.add_argument('--exe', required=True, help='Path to original executable')
    p.add_argument('--combined', help='Path to combined C/data file')
    p.add_argument('--out', help='Output directory (default: storage/results)')
    p.add_argument('--flag', default=r'FortID\{[^}]+\}', help='Regex to match flag (default: FortID{...})')
    args = p.parse_args()
    generate_exploit(args.vulns, args.typed, args.exe, None, args.out, args.flag, args.combined)


if __name__ == '__main__':
    run_cli()
